{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serverless Deep Learning\n",
    "\n",
    "We'll deploy the clothes classification model we trained previously.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  AWS Lambda\n",
    "\n",
    "* Intro to AWS Lambda\n",
    "* Serverless vs serverfull\n",
    "\n",
    "We just have to write the function, we don't need to think about the infrastructure.\n",
    "\n",
    "If there are no request we don't have to pay (We can create the function and if we don't use it it will not cost us money)\n",
    "\n",
    "`lambda_function.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    print(\"parameters:\", event)\n",
    "    url = event['url']\n",
    "    return { \"prediction\": \"pants\" }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow Lite\n",
    "\n",
    "* Why not TensorFlow\n",
    "* Converting the model\n",
    "* Using the TF-Lite model for making predictions\n",
    "\n",
    "TensorFlow is too large, this is a smaller version of TensorFlow.\n",
    "\n",
    "__Reasons__:\n",
    "\n",
    "* AWS Lambda Limits (Used to be <= 50 MB Zip File, now this is not the reason because lambda limits are up to 10GB - For Docker)\n",
    "* Larger Image = +$$$ for storage\n",
    "* Larger Image = +Time to initialize the image\n",
    "* TensorFlow is slow to import, Bigger RAM footprint\n",
    "\n",
    "TensorFlow Lite only focus on inference:\n",
    "\n",
    "* Inference is when we do `model.predict(X)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.18.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just checking the version\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('clothing-model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.applications.xception import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img('pants.jpg', target_size=(299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(img)\n",
    "X = np.array([x])\n",
    "\n",
    "X = preprocess_input(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 299, 299, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.4649577, -5.283191 , -6.699933 , -4.505825 , 13.79345  ,\n",
       "        -6.163595 , -4.2706175,  3.0697412, -3.403578 , -8.285092 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['dress', 'hat', 'longsleeve', 'outwear', 'pants', 'shirt', 'shoes', 'shorts', 'skirt', 't-shirt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dress': np.float32(-2.4649577),\n",
       " 'hat': np.float32(-5.283191),\n",
       " 'longsleeve': np.float32(-6.699933),\n",
       " 'outwear': np.float32(-4.505825),\n",
       " 'pants': np.float32(13.79345),\n",
       " 'shirt': np.float32(-6.163595),\n",
       " 'shoes': np.float32(-4.2706175),\n",
       " 'shorts': np.float32(3.0697412),\n",
       " 'skirt': np.float32(-3.403578),\n",
       " 't-shirt': np.float32(-8.285092)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(classes, preds[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Keras to TF-Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/km/dql4gckx6ps4lrl0mdrhnsbh0000gn/T/tmplkr1552n/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/km/dql4gckx6ps4lrl0mdrhnsbh0000gn/T/tmplkr1552n/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/var/folders/km/dql4gckx6ps4lrl0mdrhnsbh0000gn/T/tmplkr1552n'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='input_layer_75')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  5602721424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604507920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604508112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5602719120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604508688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604509072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604510032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604508880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604510416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604509648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604509840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604510992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604511568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604511184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604511760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604512144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604513296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604513680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604514064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604515024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604515216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604512912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604514640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604517136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604517328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604516944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604514448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604515984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604516560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604519632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604519824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604518672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604519248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604520208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604520592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604522512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604521936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604522128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604519056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604521552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604523856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604523664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604523472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5604521744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607031056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607031632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607032976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607033168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607031440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607032592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607033552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607033936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607035856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607035280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607035472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607032400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607034896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607037200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607037392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607037008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607036240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607037776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607038160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607039504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607039696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607034704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607039120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607040080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607040464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607041808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607042000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607038928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607041424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607042384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607042768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607044112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607044304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607041232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607043728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607044688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607045072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607046416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607046608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607043536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607046032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607045456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607424272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607425616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607425808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607425424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607424848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607426192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607426576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607427920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607428112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607425040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607427536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607428496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607428880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607430224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607430416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607427344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607429840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607430800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607431184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607432528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607432720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607429648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607432144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607433104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607433488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607434832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607435024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607431952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607434448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607435408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607435792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607437136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607437328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607434256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607436752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607437712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607438096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607439440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607439632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607436560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607439056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607438864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607438480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607703952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607704144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607703760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607702608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607704528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607704912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607706256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607706448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607703376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607705872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607706832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607707216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607708560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607708752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607705680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607708176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607709136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607709520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607710864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607711056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607707984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607710480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607711440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607711824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607713168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607713360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607710288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607712784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607713744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607714128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607715472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607715664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607712592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607715088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607716048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607716432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607717776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607717968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607714896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607717392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607717584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5607716816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610144592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610143824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610144784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610144016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610145552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610145936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610147280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610147472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610145168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610146896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610147856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610148240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610149584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610149776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610146704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610149200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610150160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610150544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610151888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610152080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610149008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610151504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610152464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610152848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610154192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610154384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610151312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610153808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610154768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610155152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610156496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610156688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610153616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610156112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610157072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610157456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610158800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610158992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610155920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610158416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610157840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610159760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610489424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610488656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610488080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610158224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610487888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610490768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610490960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610490576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610489808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610491344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610491728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610493072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610493264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610489040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610492688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610493648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610494032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610495376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610495568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610492496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610494992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610497104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610498064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610496912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5610499600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1732944468.879418 7355263 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732944468.879472 7355263 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2024-11-30 00:27:48.879954: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/km/dql4gckx6ps4lrl0mdrhnsbh0000gn/T/tmplkr1552n\n",
      "2024-11-30 00:27:48.886960: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2024-11-30 00:27:48.886976: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /var/folders/km/dql4gckx6ps4lrl0mdrhnsbh0000gn/T/tmplkr1552n\n",
      "I0000 00:00:1732944468.956068 7355263 mlir_graph_optimization_pass.cc:401] MLIR V1 optimization pass is not enabled\n",
      "2024-11-30 00:27:48.968971: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2024-11-30 00:27:49.505972: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /var/folders/km/dql4gckx6ps4lrl0mdrhnsbh0000gn/T/tmplkr1552n\n",
      "2024-11-30 00:27:49.633897: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 753953 microseconds.\n",
      "2024-11-30 00:27:49.723479: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('clothing-model.tflite', 'wb') as f_out:\n",
    "    f_out.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manually setting input and output indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.lite as tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "interpreter = tflite.Interpreter(model_path='clothing-model.tflite')\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'serving_default_input_layer_75:0',\n",
       "  'index': 0,\n",
       "  'shape': array([  1, 299, 299,   3], dtype=int32),\n",
       "  'shape_signature': array([ -1, 299, 299,   3], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.get_input_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_index = interpreter.get_input_details()[0]['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_index = interpreter.get_output_details()[0]['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inicializing input, invoking computations, fetching predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_index, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.invoke()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = interpreter.get_tensor(output_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dress': np.float32(-2.4649622),\n",
       " 'hat': np.float32(-5.2831907),\n",
       " 'longsleeve': np.float32(-6.6999326),\n",
       " 'outwear': np.float32(-4.505824),\n",
       " 'pants': np.float32(13.7934475),\n",
       " 'shirt': np.float32(-6.163595),\n",
       " 'shoes': np.float32(-4.2706175),\n",
       " 'shorts': np.float32(3.0697498),\n",
       " 'skirt': np.float32(-3.4035814),\n",
       " 't-shirt': np.float32(-8.285092)}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(classes, preds[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting Tensorflow code to TensorFlow Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of using load_img\n",
    "# img = load_img('pants.jpg', target_size=(299, 299))\n",
    "with Image.open('pants.jpg') as img:\n",
    "    img = img.resize((299, 299), Image.NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is what the preprocess_input method is doing\n",
    "def preprocess_input(x):\n",
    "    x /=127.5\n",
    "    x -= 1.\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(img, dtype='float32')\n",
    "X = np.array([x])\n",
    "X = preprocess_input(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_index, X)\n",
    "interpreter.invoke()\n",
    "preds = interpreter.get_tensor(output_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dress': np.float32(-2.4649622),\n",
       " 'hat': np.float32(-5.2831907),\n",
       " 'longsleeve': np.float32(-6.6999326),\n",
       " 'outwear': np.float32(-4.505824),\n",
       " 'pants': np.float32(13.7934475),\n",
       " 'shirt': np.float32(-6.163595),\n",
       " 'shoes': np.float32(-4.2706175),\n",
       " 'shorts': np.float32(3.0697498),\n",
       " 'skirt': np.float32(-3.4035814),\n",
       " 't-shirt': np.float32(-8.285092)}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = ['dress', 'hat', 'longsleeve', 'outwear', 'pants', 'shirt', 'shoes', 'shorts', 'skirt', 't-shirt']\n",
    "dict(zip(classes, preds[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simpler way of doing it\n",
    "\n",
    "```bash\n",
    "pip install keras-image-helper\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_image_helper import create_preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = create_preprocessor('xception', target_size=(299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessor.from_url\n",
    "# preprocessor.from_path\n",
    "url = 'http://bit.ly/mlbookcamp-pants'\n",
    "X = preprocessor.from_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_index, X)\n",
    "interpreter.invoke()\n",
    "preds = interpreter.get_tensor(output_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dress': np.float32(-2.4649622),\n",
       " 'hat': np.float32(-5.2831907),\n",
       " 'longsleeve': np.float32(-6.6999326),\n",
       " 'outwear': np.float32(-4.505824),\n",
       " 'pants': np.float32(13.7934475),\n",
       " 'shirt': np.float32(-6.163595),\n",
       " 'shoes': np.float32(-4.2706175),\n",
       " 'shorts': np.float32(3.0697498),\n",
       " 'skirt': np.float32(-3.4035814),\n",
       " 't-shirt': np.float32(-8.285092)}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = ['dress', 'hat', 'longsleeve', 'outwear', 'pants', 'shirt', 'shoes', 'shorts', 'skirt', 't-shirt']\n",
    "dict(zip(classes, preds[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Puting everyting together\n",
    "\n",
    "```bash\n",
    "pip install ai-edge-litert\n",
    "```\n",
    "\n",
    "Should be python 3.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dress': np.float32(-2.4649622),\n",
       " 'hat': np.float32(-5.2831907),\n",
       " 'longsleeve': np.float32(-6.6999326),\n",
       " 'outwear': np.float32(-4.505824),\n",
       " 'pants': np.float32(13.7934475),\n",
       " 'shirt': np.float32(-6.163595),\n",
       " 'shoes': np.float32(-4.2706175),\n",
       " 'shorts': np.float32(3.0697498),\n",
       " 'skirt': np.float32(-3.4035814),\n",
       " 't-shirt': np.float32(-8.285092)}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow.lite as tflite\n",
    "\n",
    "from keras_image_helper import create_preprocessor\n",
    "\n",
    "interpreter = tflite.Interpreter(model_path='clothing-model.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_index = interpreter.get_input_details()[0]['index']\n",
    "output_index = interpreter.get_output_details()[0]['index']\n",
    "\n",
    "preprocessor = create_preprocessor('xception', target_size=(299, 299))\n",
    "\n",
    "url = 'http://bit.ly/mlbookcamp-pants'\n",
    "X = preprocessor.from_url(url)\n",
    "\n",
    "interpreter.set_tensor(input_index, X)\n",
    "interpreter.invoke()\n",
    "preds = interpreter.get_tensor(output_index)\n",
    "\n",
    "classes = ['dress', 'hat', 'longsleeve', 'outwear', 'pants', 'shirt', 'shoes', 'shorts', 'skirt', 't-shirt']\n",
    "dict(zip(classes, preds[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Lambda code\n",
    "\n",
    "* Moving the code from notebook to script\n",
    "\n",
    "```bash\n",
    "jupyter nbconvert --to script serverless.ipynb\n",
    "mv serverless.py lambda_function.py\n",
    "```\n",
    "\n",
    "* Testing it locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dress': np.float32(-2.4649622),\n",
       " 'hat': np.float32(-5.2831907),\n",
       " 'longsleeve': np.float32(-6.6999326),\n",
       " 'outwear': np.float32(-4.505824),\n",
       " 'pants': np.float32(13.7934475),\n",
       " 'shirt': np.float32(-6.163595),\n",
       " 'shoes': np.float32(-4.2706175),\n",
       " 'shorts': np.float32(3.0697498),\n",
       " 'skirt': np.float32(-3.4035814),\n",
       " 't-shirt': np.float32(-8.285092)}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lambda_function\n",
    "\n",
    "event = { 'url': 'http://bit.ly/mlbookcamp-pants' }\n",
    "\n",
    "lambda_function.lambda_handler(event, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing a Docker image\n",
    "\n",
    "* Lambda base images\n",
    "\n",
    "https://gallery.ecr.aws\n",
    "\n",
    "* Preparing the dockerfile\n",
    "\n",
    "```Dockerfile\n",
    "# https://gallery.ecr.aws/lambda/python\n",
    "FROM public.ecr.aws/lambda/python:3.8\n",
    "\n",
    "RUN pip install keras-image-helper\n",
    "# RUN pip install --extra-index-url https://google-coral.github.io/py-repo/ tflite_runtime\n",
    "RUN pip install https://github.com/alexeygrigorev/tflite-aws-lambda/blob/main/tflite/tflite_runtime-2.7.0-cp38-cp38-linux_x86_64.whl?raw=true\n",
    "\n",
    "COPY clothing-model.tflite .\n",
    "COPY lambda_function.py .\n",
    "\n",
    "CMD [ \"lambda_function.lambda_handler\" ]\n",
    "\n",
    "```\n",
    "\n",
    "* Build the image\n",
    "\n",
    "```bash\n",
    "docker build --platform linux/amd64 -t clothing-model .\n",
    "```\n",
    "\n",
    "* Test the image\n",
    "\n",
    "```bash\n",
    "docker run -it --rm --platform linux/amd64 -p 8080:8080 clothing-model:latest\n",
    "```\n",
    "\n",
    "* Using the right TF-Lite wheel\n",
    "\n",
    "https://github.com/alexeygrigorev/tflite-aws-lambda\n",
    "\n",
    "https://github.com/alexeygrigorev/tflite-aws-lambda/blob/main/tflite/tflite_runtime-2.7.0-cp38-cp38-linux_x86_64.whl?raw=true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [404]>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'http://localhost:8080/2015-03-31/functions/function/invocations'\n",
    "data = { 'url': 'http://bit.ly/mlbookcamp-pants' }\n",
    "\n",
    "result = requests.post(url, json=data)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the lambda function\n",
    "\n",
    "* Publishing the image to AWS ECR\n",
    "\n",
    "```bash\n",
    "pip install awscli\n",
    "\n",
    "aws configure\n",
    "\n",
    "aws ecr create-repository --repository-name clothing-tflite-images\n",
    "\n",
    "# aws ecr get-login --no-include-email | sed 's/[0-9a-zA-Z=]\\{20,\\}/PASSWORD/g'\n",
    "\n",
    "# docker login -u AWS -p PASSWORD https://387546586014.dkr.ecr.eu-west-1.amazonaws.com\n",
    "\n",
    "$(aws ecr get-login --no-include-email)\n",
    "\n",
    "# Login Succeded\n",
    "\n",
    "ACCOUNT=387546586014\n",
    "REGION=eu-west-1\n",
    "REGISTRY=clothing-tflite-images\n",
    "PREFIX=${ACCOUNT}.dkr.ecr.${REGION}.amazonaws.com/${REGISTRY}\n",
    "TAG=clothing-model-xception-v4-001\n",
    "REMOTE_URI=${PREFIX}:${TAG}\n",
    "\n",
    "echo ${REMOTE_URI}\n",
    "\n",
    "docker tag clothing-model:latest ${REMOTE_URI}\n",
    "\n",
    "docker push ${REMOTE_URI}\n",
    "```\n",
    "\n",
    "* Creating the function\n",
    "\n",
    "    - Lambda\n",
    "    - Create function\n",
    "    - Container image\n",
    "    - Function name: clothing-classification\n",
    "    - Container image URI: --Browse Images--\n",
    "    - Click on Create Function button\n",
    "\n",
    "* Configuring it\n",
    "\n",
    "    - Configuration\n",
    "    - General Cofiguration\n",
    "    - Edit\n",
    "        - Memory: 1024 mb\n",
    "        - Timeout: 30 seconds\n",
    "\n",
    "* Testing the function from the AWS Console\n",
    "\n",
    "\n",
    "* Pricing\n",
    "\n",
    "0.0000000167 * 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### API Gateway: exposing the lambda function\n",
    "\n",
    "* Creating and configuring the gateway\n",
    "\n",
    "1. API Gateway\n",
    "    1. Create API\n",
    "    2. Rest API\n",
    "        1. Click Build\n",
    "        2. API name: clothes-classification\n",
    "        3. Click \"Create API\"\n",
    "        4. Actions -> Create Resource\n",
    "            1. Resource Name: \"predict\"\n",
    "            2. Resource Path: / \"predict\"\n",
    "            3. Click \"Create Resource\"\n",
    "        5. For the resource\n",
    "            1. Create POST Method\n",
    "                1. Integration type: Lambda Function\n",
    "                2. Lambda Region: us-east-1\n",
    "                3. Lambda Function: clothing-classification\n",
    "        6. Actions: Deploy API\n",
    "            1. Deployment stage: [New Stage]\n",
    "            2. Stage name: test\n",
    "            3. Click: \"Deploy\"\n",
    "\n",
    "\n",
    "Test with url \"https://rpa3mf7j86.execute-api.eu-west-1.amazonaws.com/test/predict\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "* AWS Lambda is a way of deploying models without having to worry about servers\n",
    "* Tensorflow Lite is a lightweight alternative to Tensorflow that only focuses on inference\n",
    "* To deploy your code, package it in a Docker container\n",
    "* Expose the lambda function via API Gateway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying BentoML to AWS lambda with Bentoctl\n",
    "\n",
    "```bash\n",
    "# Build our bento \n",
    "bentoml build\n",
    "\n",
    "# https://github.com/bentoml/bentoctl\n",
    "\n",
    "# Make sure we are connected to aws\n",
    "# aws configure\n",
    "# export AWS_PROFILE=kasteion\n",
    "aws s3 ls\n",
    "\n",
    "# Install Bentoctl\n",
    "pip install bentoctl\n",
    "\n",
    "# https://github.com/bentoml/bentoctl/aws-lambda-deployment\n",
    "\n",
    "# Instal AWS Lambda Operator\n",
    "bentoctl operator install aws-lambda\n",
    "\n",
    "# Initialize deployment with bentoctl\n",
    "mkdir deployment\n",
    "cd deployment\n",
    "\n",
    "bentoctl init\n",
    "# name: credit-risk-mlzoomcamp\n",
    "# operator:\n",
    "#   name: aws-lambda\n",
    "# template: terraform\n",
    "# spec:\n",
    "#   region: us-west-1\n",
    "#   timeout: 10\n",
    "#   memory_size: 512\n",
    "\n",
    "# Install Terraform\n",
    "brew tap hashicorp/tap\n",
    "brew install hashicorp/tap/terraform\n",
    "\n",
    "# Build command: Build lambda image & push to remote repo for AWS\n",
    "# run with --dryrun to only build the image to test locally \n",
    "bentoctl build -b credit_ristk_classifier:yq3a6zdu62jrydu5 -f deployment_config.yaml\n",
    "\n",
    "# Init terraform state file\n",
    "terraform init\n",
    "\n",
    "# Check plan\n",
    "terraform plan --var-file=bentoctl.tfvars\n",
    "\n",
    "# Apply infrastructure changes\n",
    "terraform apply --var-file=bentoctl.tfvars -auto-approve\n",
    "\n",
    "# To takedown the infrastructure from the AWS account\n",
    "bentoctl destroy -f deployment_config.yaml\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
