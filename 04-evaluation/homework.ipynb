{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_csv(\"bank-full.csv\", sep=\";\")\n",
    "features = ['age', 'job', 'marital', 'education', 'balance', 'housing', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome']\n",
    "df = df_full[features + ['y']].copy()\n",
    "df['y'] = (df['y'] == 'yes').astype(int)\n",
    "\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)\n",
    "y_full_train = df_full_train.y\n",
    "y_test = df_test.y\n",
    "y_train = df_train.y\n",
    "y_val = df_val.y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: ROC AUC feature importance\n",
    "\n",
    "ROC AUC could also be used to evaluate feature importance of numerical variables.\n",
    "\n",
    "Let's do that\n",
    "\n",
    "For each numerical variable, use it as score (aka prediction) and compute the AUC with the y variable as ground truth.\n",
    "Use the training dataset for that\n",
    "If your AUC is < 0.5, invert this variable by putting \"-\" in front\n",
    "\n",
    "(e.g. `-df_train['engine_hp']`)\n",
    "\n",
    "AUC can go below 0.5 if the variable is negatively correlated with the target variable. You can change the direction of the correlation by negating this variable - then negative correlation becomes positive.\n",
    "\n",
    "Which numerical variable (among the following 4) has the highest AUC?\n",
    "\n",
    "* balance\n",
    "* day\n",
    "* duration\n",
    "* previous\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age: 0.512185717527344\n",
      "balance: 0.5888313805382317\n",
      "day: 0.525957882383908\n",
      "duration: 0.8147002759670778\n",
      "campaign: 0.5714543015682159\n",
      "pdays: 0.5901276247352144\n",
      "previous: 0.5985653242764153\n",
      "y: 1.0\n"
     ]
    }
   ],
   "source": [
    "numerical = list(df.dtypes[df.dtypes != 'object'].keys())\n",
    "\n",
    "for column in numerical:\n",
    "    score = roc_auc_score(df_train.y, df_train[column])\n",
    "    if score < 0.5:\n",
    "        score = roc_auc_score(df_train.y, -df_train[column])\n",
    "    print(f\"{column}:\", score )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A/ `duration`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Training the model\n",
    "\n",
    "Apply one-hot-encoding using DictVectorizer and train the logistic regression with these parameters:\n",
    "\n",
    "`LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)`\n",
    "\n",
    "What's the AUC of this model on the validation dataset? (round to 3 digits)\n",
    "\n",
    "* 0.69\n",
    "* 0.79\n",
    "* 0.89\n",
    "* 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "dicts = df_train[features].to_dict(orient='records')\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X_train = dv.fit_transform(dicts)\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "dicts = df_val[features].to_dict(orient='records')\n",
    "X_val = dv.fit_transform(dicts)\n",
    "y_pred = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "auc = round(roc_auc_score(y_val, y_pred), 3)\n",
    "auc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A/ `0.89`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
