apiVersion: "serving.kserve.io/v1beta1"
kind: "InferenceService"
metadata:
  name: "churn"
spec:
  predictor:
    containers:
      image: kserve-sklearnserver:3.11-1.5.1
    model:
      modelFormat:
        name: sklearn
      storageUri: "http://172.31.13.90:8000/churn/model.joblib"
      resources:
        requests:
          cpu: 300m
          memory: 256Mi
        limits:
          cpu: 300m
          memory: 256Mi
